{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=open(\"lyrics.txt\").read()  #load the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Bidirectional,Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=data.lower().split(\"\\n\") #splitting the data to form one line sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the sentences(converting words to number) and creating a list of X and y features where every sentence is broken into the number of words it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7634\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words=len(tokenizer.word_index)+1\n",
    "\n",
    "print(total_words)\n",
    "input_lines=[]\n",
    "for line in corpus:\n",
    "  each_line=tokenizer.texts_to_sequences([line])[0]\n",
    "  for i in range(1,len(each_line)):\n",
    "    sequence=each_line[:i+1]\n",
    "    input_lines.append(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding the sentences to make sure all the sentences are of same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_line_len=max([len(x) for x in input_lines])\n",
    "input_lines=np.array(pad_sequences(input_lines,maxlen=max_line_len,padding=\"pre\"))\n",
    "\n",
    "#creating X(predictors) and Y(lables)\n",
    "pred,labels=input_lines[:,:-1],input_lines[:,-1]\n",
    "labels=ku.to_categorical(labels,num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup the model (Feel free to tune the parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 23, 100)           763400    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 23, 512)           731136    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               328192    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3817)              492393    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7634)              29146612  \n",
      "=================================================================\n",
      "Total params: 31,461,733\n",
      "Trainable params: 31,461,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(total_words,100,input_length=max_line_len-1))\n",
    "model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(total_words/2,activation=\"relu\",kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words,activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " callback = EarlyStopping(monitor='loss', patience=5)  #training will stop if loss decreases for 5 consecutive times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(pred, labels,batch_size=50, epochs=250, verbose=2,callbacks=[callback])\n",
    "model.save(\"lyricsgen.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the graphs to check the accuracy and Loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model into your systen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lyrics.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
